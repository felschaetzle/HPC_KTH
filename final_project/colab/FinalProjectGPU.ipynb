{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpIC4VRF1C4d",
        "outputId": "6edbe411-5b30-4996-ccca-8216e46e527a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.optim import Adam, SGD\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from timeit import default_timer as timer"
      ],
      "metadata": {
        "id": "IPxt7tfERjW3"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Clean Torch implementation ##\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        # Defining the model layer\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    # Definition of the forward model path\n",
        "    def forward(self, x):\n",
        "        x = F.sigmoid(self.fc1(x))\n",
        "        x = F.sigmoid(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "# Calculation of cross-entropy loss\n",
        "def cost_function(output, target):\n",
        "    loss = F.cross_entropy(output, target)\n",
        "    return loss\n",
        "\n",
        "def predict(model, X):\n",
        "    with torch.no_grad():\n",
        "        # forward path\n",
        "        output = model(X)\n",
        "        _, predicted = torch.max(output, 1)\n",
        "        return predicted\n",
        "\n",
        "def main():\n",
        "    # Load the training and test datasets\n",
        "    train = np.genfromtxt('gdrive/MyDrive/train.csv', delimiter=',')\n",
        "    test = np.genfromtxt('gdrive/MyDrive/test.csv', delimiter=',')\n",
        "\n",
        "    train_label = train[:,0].astype(int)\n",
        "    test_label = test[:,0].astype(int)\n",
        "\n",
        "    # normalization\n",
        "    train = torch.tensor(train[:,1:] / 255., dtype=torch.float32)\n",
        "    test = torch.tensor(test[:,1:] / 255., dtype=torch.float32)\n",
        "\n",
        "    X = train\n",
        "    y = torch.tensor(train_label, dtype=torch.long)\n",
        "\n",
        "    input_size = X.shape[1]\n",
        "    hidden_size = 8\n",
        "    output_size = 3\n",
        "\n",
        "    model = NeuralNetwork(input_size, hidden_size, output_size)\n",
        "    model.cuda()  # Move model to GPU\n",
        "\n",
        "\n",
        "    # Create the optimizer\n",
        "    optimizer = Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in range(600):  # Training for 10 epochs\n",
        "        optimizer.zero_grad()\n",
        "        output = model(X.cuda())  # Move input to GPU\n",
        "        loss = cost_function(output, y.cuda())  # Move target to GPU\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    train_pred = predict(model, train.cuda())  # Move input to GPU\n",
        "    test_pred = predict(model, test.cuda())  # Move input to GPU\n",
        "\n",
        "    print('accuracy on training set =', torch.sum(train_pred.cpu() == y).item() / len(train_label))\n",
        "    print('accuracy on test set =', torch.sum(test_pred.cpu() == torch.tensor(test_label)).item() / len(test_label))"
      ],
      "metadata": {
        "id": "fPQqXO7fjcLV"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Torch implementation of the original neural network sturcture\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        # create torch network levels\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "        # g(x) sigmoid activation function\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    # Definition of the forward path\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.sigmoid(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "# Loss function with added regularization term\n",
        "def cost_function(predictions, targets, criterion, model, lmbda=0):\n",
        "    loss = criterion(predictions, targets)\n",
        "    reg_loss = 0\n",
        "    for param in model.parameters():\n",
        "        reg_loss += torch.sum(torch.square(param))\n",
        "    loss += (lmbda / 2) * reg_loss\n",
        "    return loss\n",
        "\n",
        "def predict(model, X):\n",
        "    with torch.no_grad():\n",
        "        # forward path\n",
        "        outputs = model(X)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "    return predicted\n",
        "\n",
        "def main():\n",
        "    np.random.seed(917)\n",
        "\n",
        "    # Load the training and test datasets\n",
        "    train = np.genfromtxt('gdrive/MyDrive/train.csv', delimiter=',')\n",
        "    test = np.genfromtxt('gdrive/MyDrive/test.csv', delimiter=',')\n",
        "\n",
        "    # get labels (0=Elliptical, 1=Spiral, 2=Irregular)\n",
        "    train_label = train[:,0].reshape(len(train),1)\n",
        "    test_label = test[:,0].reshape(len(test),1)\n",
        "\n",
        "    # normalize image data to [0,1]\n",
        "    train = train[:,1:] / 255.\n",
        "    test = test[:,1:] / 255.\n",
        "\n",
        "    # Convert numpy arrays to PyTorch tensors\n",
        "    X_train = torch.tensor(train, dtype=torch.float32)\n",
        "    y_train = torch.tensor(train_label, dtype=torch.long)\n",
        "    X_test = torch.tensor(test, dtype=torch.float32)\n",
        "    y_test = torch.tensor(test_label, dtype=torch.long)\n",
        "\n",
        "    input_size = X_train.shape[1]\n",
        "    hidden_size = 8\n",
        "    num_classes = 3\n",
        "    learning_rate = 0.1\n",
        "    num_epochs = 600\n",
        "    lmbda = 0.0002\n",
        "\n",
        "    model = NeuralNetwork(input_size, hidden_size, num_classes)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    Js_train = []\n",
        "    Js_test = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_train)\n",
        "        loss = cost_function(outputs, y_train.squeeze(), criterion, model, lmbda)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        train_pred = predict(model, X_train)\n",
        "        train_acc = torch.sum(train_pred == y_train.squeeze()).item() / len(y_train)\n",
        "        Js_train.append(loss.item())\n",
        "\n",
        "        test_pred = predict(model, X_test)\n",
        "        test_acc = torch.sum(test_pred == y_test.squeeze()).item() / len(y_test)\n",
        "        test_loss = cost_function(model(X_test), y_test.squeeze(), criterion, model, lmbda).item()\n",
        "        Js_test.append(test_loss)\n",
        "\n",
        "    # print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss.item():.4f}, Train Acc: {train_acc:.2f}, Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}\")\n",
        "    print('accuracy on training set =', train_acc)\n",
        "    print('accuracy on test set =', test_acc)\n",
        "\n",
        "    # plt.figure(figsize=(10, 5))\n",
        "    # plt.subplot(1, 2, 1)\n",
        "    # plt.plot(Js_train, label='Train')\n",
        "    # plt.xlabel('Epoch')\n",
        "    # plt.ylabel('Loss')\n",
        "    # plt.title('Training Loss')\n",
        "    # plt.legend()\n",
        "\n",
        "    # plt.subplot(1, 2, 2)\n",
        "    # plt.plot(Js_test, label='Test')\n",
        "    # plt.xlabel('Epoch')\n",
        "    # plt.ylabel('Loss')\n",
        "    # plt.title('Test Loss')\n",
        "    # plt.legend()\n",
        "\n",
        "    # plt.show()"
      ],
      "metadata": {
        "id": "o7yOemkt_NQb"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfeuIiZEj2Q0",
        "outputId": "2bb6f6bf-652a-405d-9b89-c729a7df05c3"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy on training set = 0.5303703703703704\n",
            "accuracy on test set = 0.5525925925925926\n",
            "CPU times: user 7.42 s, sys: 70.3 ms, total: 7.49 s\n",
            "Wall time: 7.58 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iterations = 10\n",
        "total_time = 0\n",
        "\n",
        "for _ in range(iterations):\n",
        "    start_time = time.perf_counter()  # or time.time()\n",
        "    main()\n",
        "    end_time = time.perf_counter()  # or time.time()\n",
        "    total_time += (end_time - start_time)\n",
        "\n",
        "average_time = total_time / iterations\n",
        "print(f\"Average execution time: {average_time} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CprRN3rrJCd",
        "outputId": "2c0e0ff0-0c18-4575-e29b-19ae641baa30"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy on training set = 0.5774074074074074\n",
            "accuracy on test set = 0.5881481481481482\n",
            "accuracy on training set = 0.6048148148148148\n",
            "accuracy on test set = 0.6118518518518519\n",
            "accuracy on training set = 0.5955555555555555\n",
            "accuracy on test set = 0.5955555555555555\n",
            "accuracy on training set = 0.6559259259259259\n",
            "accuracy on test set = 0.6503703703703704\n",
            "accuracy on training set = 0.5396296296296297\n",
            "accuracy on test set = 0.562962962962963\n",
            "accuracy on training set = 0.5766666666666667\n",
            "accuracy on test set = 0.5866666666666667\n",
            "accuracy on training set = 0.5651851851851852\n",
            "accuracy on test set = 0.562962962962963\n",
            "accuracy on training set = 0.5637037037037037\n",
            "accuracy on test set = 0.5703703703703704\n",
            "accuracy on training set = 0.6914814814814815\n",
            "accuracy on test set = 0.6903703703703704\n",
            "accuracy on training set = 0.6037037037037037\n",
            "accuracy on test set = 0.6192592592592593\n",
            "Average execution time: 7.038278227700085 seconds\n"
          ]
        }
      ]
    }
  ]
}